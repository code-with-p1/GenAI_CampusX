{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c018f30b",
   "metadata": {},
   "source": [
    "##### Custom Chain Creation - Creating your own chain class for specialized behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "593d1bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53ed928f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Modern LangChain (v0.2+) Validation Runnable Implementation\n",
    "# ==============================\n",
    "# This version uses the LangChain Expression Language (LCEL) and the Runnable interface.\n",
    "# LLMChain, old Chain base class, and .run() are deprecated.\n",
    "# We create a custom Runnable for the validation logic.\n",
    "\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "from langchain_core.runnables import Runnable, RunnableConfig, RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a96445",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    task=\"text-generation\",\n",
    "    temperature=0.8, \n",
    "    top_p=0.95,\n",
    "    max_new_tokens=512,\n",
    ")\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56cd7571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_model.invoke(\"What is AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc0c2c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Helper: Input Validation Function\n",
    "# ==============================\n",
    "def _validate_input(inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"Custom input validation logic (returns enriched dict)\"\"\"\n",
    "    query = inputs.get(\"user_query\", \"\")\n",
    "    context = inputs.get(\"context\", \"\")\n",
    "\n",
    "    errors = []\n",
    "\n",
    "    # Check query length\n",
    "    if len(query) < 5:\n",
    "        errors.append(\"Query too short\")\n",
    "    elif len(query) > 500:\n",
    "        errors.append(\"Query too long\")\n",
    "\n",
    "    # Basic inappropriate content check\n",
    "    inappropriate_words = [\"hate\", \"violent\", \"illegal\"]\n",
    "    if any(word in query.lower() for word in inappropriate_words):\n",
    "        errors.append(\"Content may be inappropriate\")\n",
    "\n",
    "    # Context length warning\n",
    "    if context and len(context) > 1000:\n",
    "        errors.append(\"Context too long, consider summarizing\")\n",
    "\n",
    "    is_valid = len(errors) == 0\n",
    "\n",
    "    # Add validation info to the output dict\n",
    "    enriched = {\n",
    "        **inputs,\n",
    "        \"input_validation\": {\n",
    "            \"is_valid\": is_valid,\n",
    "            \"errors\": errors,\n",
    "            \"query_length\": len(query),\n",
    "            \"context_length\": len(context) if context else 0,\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if not is_valid:\n",
    "        # Return early with failure response\n",
    "        return {\n",
    "            \"response\": f\"Input validation failed: {errors}\",\n",
    "            \"validation_status\": \"failed\",\n",
    "            \"confidence_score\": 0.0,\n",
    "            \"metadata\": {\"input_validation\": enriched[\"input_validation\"], \"output_validation\": {}},\n",
    "        }\n",
    "\n",
    "    return enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fca75e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Sub-chains as Runnables (using LCEL)\n",
    "# ==============================\n",
    "\n",
    "# Preprocessing: Rephrase query\n",
    "preprocess_prompt = PromptTemplate.from_template(\n",
    "    \"Rephrase this query to be more clear and actionable: {user_query}\"\n",
    ")\n",
    "preprocess_chain = preprocess_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "# Main processing\n",
    "process_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Context: {context}\n",
    "\n",
    "    Query: {refined_query}\n",
    "\n",
    "    Provide a helpful and accurate response.\n",
    "    \"\"\"\n",
    ")\n",
    "process_chain = process_prompt | chat_model | StrOutputParser()\n",
    "\n",
    "# Output validation (JSON output for easier parsing)\n",
    "validation_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Validate if this response is:\n",
    "    1. Factually accurate (if you can determine)\n",
    "    2. Helpful and complete\n",
    "    3. Free from harmful content\n",
    "\n",
    "    Response: {response}\n",
    "\n",
    "    Return ONLY a valid JSON object with:\n",
    "    - is_valid: boolean\n",
    "    - issues: list of strings\n",
    "    - suggestions: list of strings\n",
    "    \"\"\"\n",
    ")\n",
    "validation_chain = validation_prompt | chat_model | JsonOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf9db23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Custom Validation Runnable\n",
    "# ==============================\n",
    "class ValidationRunnable(Runnable[Dict[str, Any], Dict[str, Any]]):\n",
    "    def invoke(self, inputs: Dict[str, Any], config: RunnableConfig | None = None) -> Dict[str, Any]:\n",
    "        print(\"üîç Step 1: Validating input...\")\n",
    "        validated = _validate_input(inputs)\n",
    "\n",
    "        # Early return on validation failure\n",
    "        if validated.get(\"validation_status\") == \"failed\":\n",
    "            return validated\n",
    "\n",
    "        print(\"üîÑ Step 2: Preprocessing...\")\n",
    "        refined_query = preprocess_chain.invoke({\"user_query\": validated[\"user_query\"]})\n",
    "\n",
    "        print(\"‚ö° Step 3: Processing with LLM...\")\n",
    "        response = process_chain.invoke({\n",
    "            \"context\": validated.get(\"context\", \"\"),\n",
    "            \"refined_query\": refined_query\n",
    "        })\n",
    "\n",
    "        print(\"‚úÖ Step 4: Validating output...\")\n",
    "        output_validation = validation_chain.invoke({\"response\": response})\n",
    "\n",
    "        # Calculate confidence score\n",
    "        confidence = 0.8  # base\n",
    "        if validated[\"input_validation\"][\"is_valid\"]:\n",
    "            confidence += 0.1\n",
    "        if output_validation.get(\"is_valid\", False):\n",
    "            confidence += 0.1\n",
    "\n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"validation_status\": \"success\",\n",
    "            \"confidence_score\": min(confidence, 1.0),\n",
    "            \"metadata\": {\n",
    "                \"input_validation\": validated[\"input_validation\"],\n",
    "                \"output_validation\": output_validation,\n",
    "                \"refined_query\": refined_query,\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Instantiate the custom runnable\n",
    "custom_validation_chain = ValidationRunnable()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3dc41e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MODERN VALIDATION RUNNABLE DEMO (LangChain v0.2+)\n",
      "============================================================\n",
      "\n",
      "==================================================\n",
      "TEST 1\n",
      "==================================================\n",
      "Input: {'user_query': 'How does photosynthesis work?', 'context': 'Biology educational context for high school students.'}\n",
      "üîç Step 1: Validating input...\n",
      "üîÑ Step 2: Preprocessing...\n",
      "‚ö° Step 3: Processing with LLM...\n",
      "‚úÖ Step 4: Validating output...\n",
      "\n",
      "‚úÖ Validation Status: success\n",
      "üìä Confidence Score: 1.00\n",
      "\n",
      "üí¨ Response:\n",
      "Photosynthesis is a vital process used by plants, algae, and some bacteria to convert light energy from the sun into chemical energy stored in glucose, a type of sugar. This process is crucial for life on Earth, not only because it provides food and energy to organisms but also because it helps regu...\n",
      "\n",
      "üîç Metadata:\n",
      " Input Errors: []\n",
      " Output Issues: []\n",
      "\n",
      "==================================================\n",
      "TEST 2\n",
      "==================================================\n",
      "Input: {'user_query': 'Tell me something very short', 'context': 'General knowledge'}\n",
      "üîç Step 1: Validating input...\n",
      "üîÑ Step 2: Preprocessing...\n",
      "‚ö° Step 3: Processing with LLM...\n",
      "‚úÖ Step 4: Validating output...\n",
      "\n",
      "‚úÖ Validation Status: success\n",
      "üìä Confidence Score: 1.00\n",
      "\n",
      "üí¨ Response:\n",
      "Certainly! Did you know that the largest desert in the world is the Sahara Desert, covering over 9 million square kilometers?\n",
      "\n",
      "üîç Metadata:\n",
      " Input Errors: []\n",
      " Output Issues: []\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Test the chain\n",
    "# ==============================\n",
    "print(\"=\" * 60)\n",
    "print(\"MODERN VALIDATION RUNNABLE DEMO (LangChain v0.2+)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_cases = [\n",
    "    {\n",
    "        \"user_query\": \"How does photosynthesis work?\",\n",
    "        \"context\": \"Biology educational context for high school students.\"\n",
    "    },\n",
    "    {\n",
    "        \"user_query\": \"Tell me something very short\",\n",
    "        \"context\": \"General knowledge\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, test_case in enumerate(test_cases, 1):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"TEST {i}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Input: {test_case}\")\n",
    "\n",
    "    result = custom_validation_chain.invoke(test_case)\n",
    "\n",
    "    print(f\"\\n‚úÖ Validation Status: {result['validation_status']}\")\n",
    "    print(f\"üìä Confidence Score: {result['confidence_score']:.2f}\")\n",
    "    print(f\"\\nüí¨ Response:\")\n",
    "    print(result['response'][:300] + \"...\" if len(result['response']) > 300 else result['response'])\n",
    "\n",
    "    if 'metadata' in result:\n",
    "        print(f\"\\nüîç Metadata:\")\n",
    "        print(f\" Input Errors: {result['metadata']['input_validation'].get('errors', 'None')}\")\n",
    "        print(f\" Output Issues: {result['metadata']['output_validation'].get('issues', 'None')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d770c94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai_campusx (3.10.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
